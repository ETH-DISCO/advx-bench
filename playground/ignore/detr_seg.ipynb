{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see: https://huggingface.co/facebook/detr-resnet-50-panoptic\n",
    "\n",
    "see: https://huggingface.co/facebook/detr-resnet-101-panoptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from /Users/sueszli/dev/advx-bench/data/kodak/kodim22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from transformers import DetrFeatureExtractor, DetrForSegmentation\n",
    "from transformers.models.detr.feature_extraction_detr import rgb_to_id\n",
    "\n",
    "\"\"\"\n",
    "read in model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "filename =  f'kodim{random.randint(1, 24):02d}.png'\n",
    "imgpath = Path.cwd().parent.parent / 'data' / 'kodak' / filename\n",
    "print(f'Loading image from {imgpath}')\n",
    "assert imgpath.exists(), f'Image not found at {imgpath}'\n",
    "image = Image.open(imgpath)\n",
    "\n",
    "\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "run model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-50-panoptic\")\n",
    "model = DetrForSegmentation.from_pretrained(\"facebook/detr-resnet-50-panoptic\")\n",
    "\n",
    "# prepare image for the model\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# forward pass\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# use the `post_process_panoptic` method of `DetrFeatureExtractor` to convert to COCO format\n",
    "processed_sizes = torch.as_tensor(inputs[\"pixel_values\"].shape[-2:]).unsqueeze(0)\n",
    "result = feature_extractor.post_process_panoptic(outputs, processed_sizes)[0]\n",
    "\n",
    "# the segmentation is stored in a special-format png\n",
    "panoptic_seg = Image.open(io.BytesIO(result[\"png_string\"]))\n",
    "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8)\n",
    "# retrieve the ids corresponding to each mask\n",
    "panoptic_seg_id = rgb_to_id(panoptic_seg)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "visualize image\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "visualize panoptic segmentation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "# for elem in result[\"segments_info\"]:\n",
    "#     elem_id = elem[\"id\"] # unique id of the mask\n",
    "#     elem_name = model.config.id2label[elem[\"category_id\"]] # name of the class (e.g. 'horse')\n",
    "#     elem_area = elem[\"area\"] # number of pixels of the mask in the image\n",
    "#     print(f\"Mask {elem_id} is a {elem_name} with area {elem_area}\")\n",
    "\n",
    "# ax.imshow(panoptic_seg_id)\n",
    "# plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.imshow(panoptic_seg_id)\n",
    "plt.title(\"Panoptic Segmentation\", fontsize=16)\n",
    "\n",
    "# add labels for each segment\n",
    "for elem in result[\"segments_info\"]:\n",
    "    elem_id = elem[\"id\"]\n",
    "    elem_name = model.config.id2label[elem[\"category_id\"]]\n",
    "    elem_area = elem[\"area\"]\n",
    "    \n",
    "    # Find the center of the segment\n",
    "    y, x = np.where(panoptic_seg_id == elem_id)\n",
    "    if len(x) > 0 and len(y) > 0:\n",
    "        center_x, center_y = np.mean(x), np.mean(y)\n",
    "        ax.annotate(elem_name, (center_x, center_y), color='white', fontweight='bold', ha='center', va='center', bbox=dict(facecolor='black', alpha=0.5, pad=1))\n",
    "\n",
    "plt.xlabel(\"X-axis (pixels)\", fontsize=12)\n",
    "plt.ylabel(\"Y-axis (pixels)\", fontsize=12)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
